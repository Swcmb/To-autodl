

命令相同的部分：python main.py --file dataset1/LDA.edgelist --neg_sample dataset1/non_LDA.edgelist --validation_type 5-cv1 --task_type LDA --feature_type normal --similarity_threshold 0.5 --embed_dim 64 --learning_rate 0.0005 --weight_decay 0.0005 --epochs 3 --alpha 0.5 --beta 0.5 --gamma 0.5

不相同的是编码器不一样：

1. csglmd（本地 CSGLMD，EM/layer.py）

- 架构：两层 GCNConv（图卷积）+ PReLU 激活；图级读出 AvgReadout + Sigmoid + 线性层；包含对比学习判别器 Discriminator 和简化对抗项；解码器为加/乘/拼接的交互特征经两层线性输出。

- 输入输出：forward(data_o, data_a, idx)；输出 (log, ret_os, ret_os_a, x2_o, logits, log1)。其中 log 为最终分数，x2_o 为节点嵌入，ret_os*_ 为对比项，logits 为对抗项。

- 依赖：torch_geometric.nn.GCNConv。

- 适用场景：与当前数据管线、任务偏移规则（LDA/MDA/LMI）完全对齐，复现稳定。

- 可调参数：dimensions、hidden1、hidden2、decoder1、dropout、lr、weight_decay、loss_ratio(1-4)。

- 兼容性：EM 主流程默认架构；通过 --encoder_type csglmd 使用。

- 结果：

- AUROC: 0.9369 ± 0.0048
  AUPRC: 0.9422 ± 0.0052
  F1-Score: 0.8469 ± 0.0182
  Loss: 0.2955 ± 0.1199

  Detailed Results:
  Fold 1: AUROC=0.9338, AUPRC=0.9395, F1=0.8285
  Fold 2: AUROC=0.9313, AUPRC=0.9370, F1=0.8269
  Fold 3: AUROC=0.9369, AUPRC=0.9411, F1=0.8438
  Fold 4: AUROC=0.9456, AUPRC=0.9522, F1=0.8712
  Fold 5: AUROC=0.9370, AUPRC=0.9413, F1=0.8644

1. mgacmda（外部 MGACMDA/gate.py 的 GraphAttentionEncoder 适配）

- 架构：多头 GAT（GraphAttentionLayer）堆叠 + 残差；每层后 ReLU+Dropout；最终可选 FC；我们适配后仍保持对比项与统一解码器。
- 输入输出：forward(data_o, data_a, idx)；内部将 edge_index 转密集邻接 A，调用 GraphAttentionEncoder(A, X)；输出结构与统一接口一致。
- 依赖：MGACMDA/gate.py；纯 PyTorch 实现（非 torch_geometric 的 GATConv）。
- 适用场景：希望复用 MGACMDA 的 GAT 编码器风格或进行对比。
- 可调参数：dimensions、hidden1、hidden2、gat_heads（作为 num_heads）、dropout、decoder1。
- 兼容性：--encoder_type mgacmda。
- 结果：
  

1. gat（基于 torch_geometric 的图注意力网络）

- 架构：GATConv 第一层（concat=True, heads=h）+ PReLU + Dropout；GATConv 第二层（concat=False, heads=1）+ PReLU；图级读出/对比/对抗/解码与 CSGLMD 对齐。
- 输入输出：forward(data_o, data_a, idx)；直接用 edge_index。
- 依赖：torch_geometric.nn.GATConv。
- 适用场景：引入注意力机制以增强邻域选择与权重分配。
- 可调参数：gat_heads、hidden1、hidden2、dropout、decoder1 等。
- 兼容性：--encoder_type gat（已在 5 折验证正常）。

1. gt（基于 torch_geometric 的 Graph Transformer）

- 架构：TransformerConv 第一层（concat=True, heads=h）+ PReLU + Dropout；TransformerConv 第二层（concat=False, heads=1）+ PReLU；其余组件与统一接口相同。
- 输入输出：forward(data_o, data_a, idx)。
- 依赖：torch_geometric.nn.TransformerConv。
- 适用场景：更强的注意力表达与多头聚合，适用于复杂异构或长程依赖的图。
- 可调参数：gt_heads、hidden1、hidden2、dropout、decoder1。
- 兼容性：--encoder_type gt。

1. gat_gt_serial（串联：GAT -> GT）

- 架构：先用 GATConv 进行初级注意力编码（concat=True, heads=gat_heads），再接 TransformerConv（concat=False），实现“先邻域注意力，再全局 Transformer”的层次化编码。
- 输入输出：forward(data_o, data_a, idx)；其余组件与统一接口一致。
- 依赖：GATConv + TransformerConv。
- 适用场景：在数据上先做局部注意力抽取再做全局交互的两阶段编码。
- 可调参数：gat_heads、gt_heads、hidden1、hidden2、dropout、decoder1。
- 兼容性：--encoder_type gat_gt_serial。

1. gat_gt_parallel（并联：GAT || GT）

- 架构：两个分支并行编码（GATConv 堆叠 与 TransformerConv 堆叠），将两个分支的输出 concat 后用线性层融合到统一 hidden2，再进行读出/对比/解码。
- 输入输出：forward(data_o, data_a, idx)；融合层 fuse: Linear(2*hidden2 -> hidden2)。
- 依赖：GATConv + TransformerConv。
- 适用场景：同时利用两种注意力机制的互补性，兼顾局部与全局表达。
- 可调参数：gat_heads、gt_heads、hidden1、hidden2、dropout、decoder1。
- 兼容性：--encoder_type gat_gt_parallel。